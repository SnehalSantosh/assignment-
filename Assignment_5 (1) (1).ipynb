{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_qGjWZO9iws"
   },
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aO0jLGbn9iw3"
   },
   "source": [
    "### Use this notebook to complete the Assignment 5\n",
    "### This gives a base program to complete modules in Assignment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcWwPuFd9iw4"
   },
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Cfn9KOI9iw6"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext, DataFrame\n",
    "from pyspark.sql.functions import desc,monotonically_increasing_id,sum,lit,col\n",
    "\n",
    "import os\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF0hMc5-9iw7"
   },
   "source": [
    "#### This program works only for Spark 3.0 and Scala 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntfJ3fW89iw8"
   },
   "outputs": [],
   "source": [
    "SUBMIT_ARGS = \"--packages graphframes:graphframes:0.8.0-spark3.0-s_2.12 pyspark-shell\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = SUBMIT_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5w1M1kL9iw9"
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('GraphFrames').setMaster('local')\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KSXyQqu9iw9"
   },
   "outputs": [],
   "source": [
    "from graphframes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-71zicc9iw-"
   },
   "outputs": [],
   "source": [
    "# Useful functions to explore before this assignment\n",
    "# 1. Dataframe's select\n",
    "# 2. Dataframe's groupBy\n",
    "# 3. Dataframe's df.schema.names\n",
    "# 4. Dataframe's df.printSchema()\n",
    "# 5. Dataframe's take()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JWUYCx-9iw-"
   },
   "source": [
    "### Module - 1: Data cleaning and processing\n",
    "### Steps:\n",
    "#### 1. Use wiki_tiny.txt as data for this Assignment\n",
    "#### 2. Create dataRDD from the input file\n",
    "#### 3. The data is very similar to Assignment-3. But this time it is structured as <title>Doc title</title><text>Doc content</text>, where the Doc content contains many URLs as [[URL]]\n",
    "#### 4. Write a regular Spark program to clean the Doc content and get all edges represented as (Doc title, url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8bj3a-Ji9iw_"
   },
   "outputs": [],
   "source": [
    "# Give data path here\n",
    "data_path = 'wiki_tiny.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWFbFPmm9ixB"
   },
   "outputs": [],
   "source": [
    "dataRDD = sc.textFile(data_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKWZyVH29ixC"
   },
   "outputs": [],
   "source": [
    "# Function to clean the text \n",
    "# 1. Get title and text of each document. URLs in documents are represented by [[URL]] and it should be retrieved using regular expressions\n",
    "# 2. URLs in each document may have special cases. Example: [[source:background.jpeg|Background]]. \n",
    "#                                                  For such cases consider only \"source:background.jpeg\" as URL\n",
    "# 3. The function should return a list of tuples (title,URL) - Figure out how to achieve that\n",
    "def get_edges(line):\n",
    "    to_return = []\n",
    "\n",
    "    # Complete the data processing steps here\n",
    "\n",
    "    return to_return\n",
    "# Figure out which Spark transformation function to use here\n",
    "# From a document (wikipedia page), in the given file, we need a list of (title,URL)\n",
    "# Replace \"transformation\" from the following line to the corresponding function name. Example replace it with \"map\"\n",
    "edgesRDD = dataRDD.transformation(get_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_Oqr5O99ixD"
   },
   "source": [
    "### Module - 2: Graph creation \n",
    "### Steps:\n",
    "#### 1. Create edges dataframe\n",
    "#### 2. Create vertices dataframe from edges\n",
    "#### 3. Create graph dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6TSnV8B9ixE"
   },
   "outputs": [],
   "source": [
    "# TASK 2.1\n",
    "# Convert edgesRDD to a dataframe (edgesDF)\n",
    "# The edgesRDD columns should be named \"src\" and \"dst\"\n",
    "# HINT: Use toDF()\n",
    "edgesDF = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ajtcHoa9ixG"
   },
   "outputs": [],
   "source": [
    "# TASK 2.2\n",
    "# Get dataframes for source and destination vertices from edgesDF's src and dst columns respectively\n",
    "# Each of these dataframes should only have unique values - no duplicates - as we need a unique list of vertex names to create 'id'\n",
    "# Complete the following statements\n",
    "srcDF = edgesDF.\n",
    "destDF = edgesDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtEvO8dk9ixH"
   },
   "outputs": [],
   "source": [
    "# TASK 2.3\n",
    "# Union vertices from srcDF and destDF, which will give back another dataframe (named verticesDF) with only one column\n",
    "# HINT: Use python functools's reduce function \n",
    "\n",
    "# Complete the following statement to union\n",
    "verticesDF = \n",
    "\n",
    "# Rename the column as \"Page\" and assign back to the same variable (verticesDF)\n",
    "verticesDF = verticesDF.\n",
    "\n",
    "# Add an ID column to the dataframe and assign back to the same variable (verticesDF)\n",
    "# HINT: Use monotonically_increasing_id()\n",
    "verticesDF = verticesDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "boJYv0Tf9ixH"
   },
   "outputs": [],
   "source": [
    "# Create a graphframe from verticesDF and edgesDF\n",
    "G = GraphFrame(verticesDF,edgesDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REUe9MdE9ixI"
   },
   "source": [
    "### Module - 3: Basic queries on the constructed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wfJg-Cm9ixI"
   },
   "outputs": [],
   "source": [
    "# TASK 3.1\n",
    "# Write a query to show number of vertices in the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDc6_aME9ixI"
   },
   "outputs": [],
   "source": [
    "# TASK 3.2\n",
    "# Write a query to show number of edges in the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2iznRdP9ixJ"
   },
   "outputs": [],
   "source": [
    "# TASK 3.3\n",
    "# 1. Get indegrees of the graph\n",
    "# 2. Sort them in descending order \n",
    "# 3. Display only top 15 rows of the dataframe\n",
    "# The output will display which page in wikipedia is having more in-links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiDK4yTS9ixJ"
   },
   "outputs": [],
   "source": [
    "# TASK 3.4\n",
    "# 1. Get degrees of the graph\n",
    "# 2. Sort them in descending order \n",
    "# 3. Display only top 15 rows of the dataframe\n",
    "# The output will display which page in wikipedia is having more links(sum of in-links and out-links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIJU1fHo9ixL"
   },
   "outputs": [],
   "source": [
    "# TASK 3.5\n",
    "# 1. Get number of multiple edges between nodes in graph G\n",
    "# The graph created from Wikipedia articles have multiple edges. Example: 150 edges from the node \"April\" to the node \"August\"\n",
    "# This means there the page \"April\" has reference the page \"August\" 150 times\n",
    "# 2. The resulting dataframe should have only three columns: \"src\", \"dst\", and \"count\", where count is number of edges between \"src\" and \"dst\"\n",
    "# 3. Sort the dataframe is descending order\n",
    "# 4. Display only top 15 rows of the dataframe\n",
    "# HINT: This can be achieved with a sequence of very simple dataframe commands \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy86bs_n9ixL"
   },
   "source": [
    "### Module - 4: Message Aggregation - Page Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3SyT5Tv9ixM"
   },
   "outputs": [],
   "source": [
    "# 1. Get the graph G's outdegree to outDegDF\n",
    "outDegDF = \n",
    "\n",
    "# 2. Join outDegDF and verticesDF. Assign the joined dataframes to verticesDF\n",
    "# 3. Finally, verticesDF should have only 3 columns: id, Page, and outDegree \n",
    "verticesDF = \n",
    "\n",
    "# 4. Create a new graph new_G with new verticesDF and existing edgesDF\n",
    "new_G = GraphFrame(verticesDF,edgesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-4fbfd_MqkQ"
   },
   "outputs": [],
   "source": [
    "# 1. Write an aggregateMessages function on 'new_G' to sum neighbors' outDegree for each vertex \n",
    "# [NOTE: messages should pass only via the edge direction, not in both ways as discussed in the lecture]\n",
    "# 2. The aggregated outDegree will be the rank of a page (higher the rank of a page, higher its importance )\n",
    "# 3. Show top 15 very important pages along with their rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-eXJyCdKFQfj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment-5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
